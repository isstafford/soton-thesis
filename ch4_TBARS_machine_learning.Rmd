---
title: "Random Forest for Predicting TBARS Assay Results from Oxidative Stress Genes "
author: "Imogen Stafford"
date: "11/10/2019"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Load Packages from Library 

```{r}
library(caret)
library(tidyverse)
library(randomForest)
library(gbm)
library(kernlab)
library(MLmetrics)
library(pROC)
library(RWeka)
```


#Load up and Configure Data

```{r}
rosdata <- read.delim("../rosdatanew.txt")

MyVars <- c( "tbars_final_z","NOX1", "CYBA", "CYBB", "NCF2","NCF4",  "RAC2",
             "DUOX2", "NOXA1","NOXO1", "DUOXA1", "DUOXA2", "DUOX1", "NOX3", "NOX4", "NOX5")

mldata <- na.omit(rosdata[MyVars])
```

#Label FRAP assay results as "high", "mid", "low". Make a new column in the dataframe for this information.

```{r}
mldata$tbars_bin <- mldata$tbars_final_z
mldata$tbars_bin[mldata$tbars_final_z > quantile(mldata$tbars_final_z, probs = 0.75)] <- print("high")
mldata$tbars_bin[mldata$tbars_final_z < quantile(mldata$tbars_final_z, probs = 0.25)] <- print("low")
mldata$tbars_bin[mldata$tbars_final_z >= quantile(mldata$tbars_final_z, probs = 0.25)  & mldata$tbars_final_z <= quantile(mldata$tbars_final_z, probs = 0.75)] <- print("mid")
mldata$tbars_bin <- as.factor(mldata$tbars_bin)

#Check categories are in their correct proportion
summary(mldata$tbars_bin)

#Remove frap z-scores
mldata <- mldata[,-1]

#Remove data in "mid" category
data <- subset(mldata, tbars_bin=="high" | tbars_bin=="low")

#remove mid level
data$tbars_bin <- factor(data$tbars_bin)
summary(data$tbars_bin)

```

#FRAP model: remove midpoindata splitting

```{r}
#begin data partition
set.seed(23)
trainIndex <- createDataPartition(data$tbars_bin, p = .8, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)

tbarsTrain <- data[ trainIndex,]
tbarsTest  <- data[-trainIndex,]
summary(tbarsTrain$tbars_bin)
summary(tbarsTest$tbars_bin)

preProcValues <- preProcess(tbarsTrain, method = c("center", "scale"))

training <- predict(preProcValues, tbarsTrain)
testing <- predict(preProcValues, tbarsTest)

```

#Model Training

```{r}
set.seed(23)
ctrl <- trainControl (##10-fold CV
  method = "repeatedcv",
  repeats=5,
   summaryFunction=twoClassSummary,# Use AUC to pick the best model
  classProbs=TRUE)
#method="rf"
mtry <- sqrt(ncol(training))
set.seed(23)
rfFit <- train(tbars_bin ~ ., data = training, method ="rf", metric="ROC", Mtry = mtry, trControl = ctrl )

rfFit


#method="gbm"
set.seed(23)
gbmGrid <-  expand.grid(interaction.depth = c(1,3, 5, 7, 9), 
                        n.trees = (1:30)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20)

gbmFit2 <- train(tbars_bin ~ ., data = training, 
                 method = "gbm", 
                 trControl = ctrl, 
                 verbose = FALSE, 
                 ## Now specify the exact models 
                 ## to evaluate:
                 tuneGrid = gbmGrid)
gbmFit2
plot(gbmFit2)


#method="lssmv"
set.seed(23)
grid <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25, 1.5, 1.75))
lsvmfit <- train(tbars_bin ~ ., data = training, 
                 method = "svmLinear", tuneGrid = grid,
                 trControl = ctrl, metric="ROC")
lsvmfit


#method="smv radial"
set.seed(23)
grid <- expand.grid(sigma = c(.01, .015, 0.2, 0.25),
                    C = c(0.75, 0.9, 1, 1.1, 1.25))

psvmfit <- train(tbars_bin ~ ., data = training, 
                 method = "svmRadial", tuneGrid = grid,
                 trControl = ctrl, metric="ROC")
psvmfit


#Logistic Model Trees
set.seed(23)

grid <- expand.grid(iter = c(1, 20, 40, 60, 80, 100, 150, 200, 250, 300, 400, 500))
lmtfit <- train(tbars_bin ~ ., data = training, 
                 method = "LMT", tuneGrid = grid,
                 trControl = ctrl, metric="ROC")
lmtfit

#Model Comparison
rValues <- resamples(list(rfFit, gbmFit2, lsvmfit, psvmfit, lmtfit))
     
bwplot(rValues,metric="ROC",ylab =c("Tested Models"), par.settings=list(box.rectangle=list(col="black",fill="cyan4",alpha=1),box.umbrella=list(col="black",alpha=1)))
```

#Feature Importance
```{r}
varImp(rfFit, scale=FALSE)
varImp(gbmFit2, scale=FALSE)
varImp(lsvmfit, scale=FALSE)
varImp(psvmfit, scale=FALSE)
varImp(lmtfit, scale=FALSE)
```


#Test set Predictions
```{r}
predict.test <- predict(psvmfit, newdata = testing)
predict.prob <- predict(psvmfit, newdata=testing, type = "prob")
str(predict.test)
str(predict.prob)
predict.test
confusionMatrix(data= predict.test, testing$tbars_bin)

#precrec for AUC and precision-recall curves

precrec_obj <- evalmod(scores = 1 - predict.prob$high, labels = testing$tbars_bin)
precrec_obj <- evalmod(scores = predict.prob$low, labels = testing$tbars_bin)
autoplot(precrec_obj)
```






